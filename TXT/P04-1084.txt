Generalized Multitext Grammars
I. Dan Melamed
Computer Science Department
New York University
715 Broadway, 7th Floor
New York, NY, 10003, USA
 
lastname� @cs.nyu.edu
Giorgio Satta
Dept. of Information Eng'g
University of Padua
via Gradenigo 6/A
I-35131 Padova, Italy
 
lastname� @dei.unipd.it
Benjamin Wellington
Computer Science Department
New York University
715 Broadway, 7th Floor
New York, NY, 10003, USA
 
lastname� @cs.nyu.edu
Abstract
Generalized Multitext Grammar (GMTG) is a synchronous grammar formalism that is weakly equivalent to Linear Context-Free Rewriting Systems
(LCFRS), but retains much of the notational and intuitive simplicity of Context-Free Grammar (CFG).
GMTG allows both synchronous and independent
rewriting. Such flexibility facilitates more perspicuous modeling of parallel text than what is possible
with other synchronous formalisms. This paper investigates the generative capacity of GMTG, proves
that each component grammar of a GMTG retains
its generative power, and proposes a generalization
of Chomsky Normal Form, which is necessary for
synchronous CKY-style parsing.
1 Introduction
Synchronous grammars have been proposed for
the formal description of parallel texts representing
translations of the same document. As shown by
Melamed (2003), a plausible model of parallel text
must be able to express discontinuous constituents.
Since linguistic expressions can vanish in translation, a good model must be able to express independent (in addition to synchronous) rewriting. Inversion Transduction Grammar (ITG) (Wu, 1997)
and Syntax-Directed Translation Schema (SDTS)
(Aho and Ullman, 1969) lack both of these properties. Synchronous Tree Adjoining Grammar
(STAG) (Shieber, 1994) lacks the latter and allows
only limited discontinuities in each tree.
Generalized Multitext Grammar (GMTG) offers
a way to synchronize Mildly Context-Sensitive
Grammar (MCSG), while satisfying both of the
above criteria. The move to MCSG is motivated
by our desire to more perspicuously account for
certain syntactic phenomena that cannot be easily
captured by context-free grammars, such as clitic
climbing, extraposition, and other types of longdistance movement (Becker et al., 1991). On the
other hand, MCSG still observes some restrictions
that make the set of languages it generates less expensive to analyze than the languages generated by
(properly) context-sensitive formalisms.
More technically, our proposal starts from Multitext Grammar (MTG), a formalism for synchronizing context-free grammars recently proposed by
Melamed (2003). In MTG, synchronous rewriting
is implemented by means of an indexing relation
that is maintained over occurrences of nonterminals
in a sentential form, using essentially the same machinery as SDTS. Unlike SDTS, MTG can extend
the dimensionality of the translation relation beyond two, and it can implement independent rewriting by means of partial deletion of syntactic structures. Our proposal generalizes MTG by moving
from component grammars that generate contextfree languages to component grammars whose generative power is equivalent to Linear Context-Free
Rewriting Systems (LCFRS), a formalism for describing a class of MCSGs. The generalization is
achieved by allowing context-free productions to
rewrite tuples of strings, rather than single strings.
Thus, we retain the intuitive top-down definition of
synchronous derivation original in SDTS and MTG
but not found in LCFRS, while extending the generative power to linear context-free rewriting languages. In this respect, GMTG has also been inspired by the class of Local Unordered Scattered
Context Grammars (Rambow and Satta, 1999). A
syntactically very different synchronous formalism
involving LCFRS has been presented by Bertsch
and Nederhof (2001).
This paper begins with an informal description of
GMTG. It continues with an investigation of this
formalism's generative capacity. Next, we prove
that in GMTG each component grammar retains its
generative power, a requirement for synchronous
formalisms that Rambow and Satta (1996) called
the "weak language preservation property." Lastly,
we propose a synchronous generalization of Chomsky Normal Form, which lays the groundwork for
synchronous parsing under GMTG using a CKYstyle algorithm (Younger, 1967; Melamed, 2004).
2 Informal Description and Comparisons
GMTG is a generalization of MTG, which is itself
a generalization of CFG to the synchronous case.
Here we present MTG in a new notation that shows
the relation to CFG more clearly. For example, the
following MTG productions can generate the multitext [(I fed the cat), (ya kota kormil)]:1
 (S)�(S)���  ��PN�VP��� �PN�VP��� (1)
 �PN�� �PN���  ��I�� �ya�� (2)
 �VP�� �VP���  ��V� NP� �� �NP� V� �� (3)
 �V�� �V���  ��fed�� �kormil�� (4)
 �NP�� �NP���  ��D� N� �� �N� �� (5)
 ��D�� ����  ��the�� ��� (6)
 �N�� �N���  ��cat�� �kota�� (7)
Each production in this example has two components, the first modeling English and the second (transliterated) Russian. Nonterminals with the
same index must be rewritten together (synchronous
rewriting). One strength of MTG, and thus also
GMTG, is shown in Productions (5) and (6). There
is a determiner in English, but not in Russian, so
Production (5) does not have the nonterminal D in
the Russian component and (6) applies only to the
English component (independent rewriting). Formalisms that do not allow independent rewriting require a corresponding  to appear in the second
component on the right-hand side (RHS) of Production (5), and this  would eventually generate the
empty string. This approach has the disadvantage
that it introduces spurious ambiguity about the position of the "empty" nonterminal with respect to
the other nonterminals in its component. Spurious
ambiguity leads to wasted effort during parsing.
GMTG's implementation of independent rewriting through the empty tuple () serves a very different function from the empty string. Consider the
following GMTG:
 �� �� � ���  ��! �� �!" �� (8)
 �� �� � ���  ��$# � �� �!% � �� (9)
 ��$# �� ����  ��'& �� ���)(  ��!0 �� ���1(  ��!2 �� ��� (10)
 ���� �!% ��3�  ���� �'4 ��1(  ���� �'5 ��1(  ���� �76 �� (11)
Production (8) asserts that symbol vanishes in
translation. Its application removes both of the nonterminals on the left-hand side (LHS), pre-empting
any other production. In contrast, Production (9)
1
We write production components both side by side and one
above another to save space, but each component is always in
parentheses.
explicitly relaxes the synchronization constraint, so
that the two components can be rewritten independently. The other six productions make assertions
about only one component and are agnostic about
the other component. Incidentally, generating the
same language with only fully synchronized productions would raise the number of required productions to 11, so independent rewriting also helps
to reduce grammar size.
Independent rewriting is also useful for modeling paraphrasing. Take, for example, [(Tim got a
pink slip), (Tim got laid off)]. While the two sentences have the same meaning, the objects of their
verb phrases are structured very differently. GMTG
can express their relationships as follows:
 ��S�� �S���  ��NP�VP��� �NP�VP�8�� (12)
 ��VP�� �VP����  ��V�NP� �� �V�PP� �� (13)
 �NP�� �PP����  ��DT�A�9�N@�� �VBAB�RC�� (14)
 ��NP�� �NP����  ��Tim�� � Tim�� (15)
 D�V�� �V���  ��got�� �got�� (16)
 D�DT�� ����  ��a�� ��� (17)
 ��A�� ����  ��pink�� ��� (18)
 ��N�� ����  ��slip�� ��� (19)
 D��� �VB���  ���� �laid�� (20)
 ���� �R���  ���� �off�� (21)
As described by Melamed (2003), MTG requires
production components to be contiguous, except after binarization. GMTG removes this restriction.
Take, for example, the sentence pair [(The doctor
treats his teeth), (El m�
edico le examino los dientes)]
(Dras and Bleam, 2000). The Spanish clitic le and
the NP los dientes should both be paired with the
English NP his teeth, giving rise to a discontinuous
constituent in the Spanish component. A GMTG
fragment for the sentence is shown below:
 ��S�� �S����  ��NP�VP� �� �NP� VP� ��
 ��VP�� �VP��3�  ��V� NP� �� �NP� V�NP� ��
 ��NP�� �NP��3�  ��The doctor�� �El m�
edico��
 ��V�� �V����  ��treats�� �examino��
 ��NP�� �NP� NP��3�  ��his teeth�� �le� los dientes��
Note the discontinuity between le and los dientes.
Such discontinuities are marked by commas on both
the LHS and the RHS of the relevant component.
GMTG's flexibility allows it to deal with many
complex syntactic phenomena. For example,
Becker et al. (1991) point out that TAG does not
have the generative capacity to model certain kinds
of scrambling in German, when the so-called "cooccurrence constraint" is imposed, requiring the
derivational pairing between verbs and their complements. They examine the English/German sentence fragment [(... that the detective has promised
the client to indict the suspect of the crime), (...
da� des Verbrechens der Detektiv den Verd�
achtigen
dem Klienten zu �
uberf�
uhren versprochen hat)]. The
verbs versprochen and �
uberf�
uhren both have two
noun phrases as arguments. In German, these noun
phrases can appear to the left of the verbs in any
order. The following is a GMTG fragment for the
above sentence pair2:
  �S�
�S���
� �
�N������ has promised N��� ���S@ �
� S@ N� ���S@ N�  ��!S@ versprochen hat�#"
(22)
  � S�
� S� S� S��
�
  �to indict N�$&%'$( �&��� N���)0213� �
�N�4 ��)�5 �N�4 ��)6� � zu �
uberf�
uhren��
(23)
The discontinuities allow the noun arguments of
versprochen to be placed in any order with the noun
arguments of �
uberf�
uhren. Rambow (1995) gives a
similar analysis.
3 Formal Definitions
Let 798 be a finite set of nonterminal symbols and
let @ be the set of integers.3 We define A
�7 8 �CB
DFEHGPI6Q
( ESR
7 8 �UT
R
@WV .4 Elements of A
�7 8 �
will be called indexed nonterminal symbols. In
what follows we also consider a finite set of terminal symbols 7YX , disjoint from 7 8 , and work with
strings in 7a`
b , where 7 b BcA
�7 8 �de7YX . For f
R
7g`
b ,
we define hiqpsrut
�f �vB
D
T (3fwBxfy
E GPI6Q
f9y y$�fy7�fy y
R
7 `
b � EGI6QR
A
�7 8 �V , i.e. the set of indexes that appear in f .
An indexed tuple vector, or ITV, is a vector of
tuples of strings over 7 b , having the form
f B
 ��f
� � � �f
��
�� � �f
� ��fY
�
��
where  , ed and ffhg
R
7 `
b for gikjei  ,
imlnio . We write f
 j�, iojpi  , to denote the
j -th component of f and q
�f
 j'�$� to denote the arity
of such a tuple, which is F . When q
�f
 j'�$�rBsd ,
f
 j� is the empty tuple, written
��. This should not
be confused with
�!" �, that is the tuple of arity one
containing the empty string. A link is an ITV where
2
These are only a small subset of the necessary productions.
The subscripts on the nonterminals indicate what terminals they
will eventually yield; the terminal productions have been left
out to save space.
3
Any other infinite set of indexes would suit too.
4
The parentheses around indexes distinguish them from
other uses of superscripts in formal language theory. However,
we shall omit the parentheses when the context is unambiguous.
each fftg consists of one indexed nonterminal and all
of these nonterminals are coindexed. As we shall
see, the notion of a link generalizes the notion of
nonterminal in context-free grammars: each production rewrites a single link.
Definition 1 Let    be some integer constant. A generalized multitext grammar with 
dimensions ( -GMTG for short) is a tuple uvB
�798 �u7 X ��w �  � where 798 , 7 X are finite, disjoint sets
of nonterminal and terminal symbols, respectively,
xR
7 8 is the start symbol and w is a finite set of
productions. Each production has the form y � z ,
where y is a  -dimensional link and z is a  dimensional ITV such that q
�y
 j'�$�{B|q
�z
 j'�$� for
i}jpi  . If y
 j'� contains
 , then q
�y
 j'�$�B~ .
We omit symbol  from  -GMTG whenever it is
not relevant. To simplify notation, we write productions as B
 
� ��& �, with each 9B
�&E

� � � E

�
� � �y 
� � �y 
�
�,
E
hg
R
798 . I.e.
we omit the unique index appearing on the LHS of
 . Each   is called a production component. The
production component
�� � �� is called the inactive
production component. All other production components are called active and we set quh r
� �B
D
j (dfV . Inactive production components are
used to relax synchronous rewriting on some dimensions, that is to implement rewriting on
2U
 components. When
2 B , rewriting is licensed on one
component, independently of all the others.
Two grammar parameters play an important role
in this paper. Let B
 
� ��& � R
w and B
�&E

� � � E

�
� � �y 
� � �y 
�
�.
Definition 2 The rank  of a production  is
the number of links on its RHS: 
� � B
(2hPiprut
�y
� � 
y
���
y
� �!
y
�
�8(. The rank of a
GMTG u is 
�u �BC 
� �.
Definition 3 The fan-out of   ,  and u are, respectively, q
�  �B|  , q
� �B 

��
� q
�  � and
q
�u �BxC ��q
� �.
For example, the rank of Production (23) is two and
its fan-out is four.
In GMTG, the derives relation is defined over
ITVs. GMTG derivation proceeds by synchronous
application of all the active components in some
production. The indexed nonterminals to be rewritten simultaneously must all have the same index T ,
and all nonterminals indexed with T in the ITV must
be rewritten simultaneously. Some additional notation will help us to define rewriting precisely. A
reindexing is a one-to-one function on @ , and is
extended to 7 b by letting
5 �! ��B for
�R
7�X
and
5 �&EHGPI6Q
�B
EHG� GPI6Q6Q
for
EHGI6QxR
A
�7 8 �. We
also extend
5 to strings in 7 `
b analogously. We
say that y �y y
R
7 `
b are independent if hiqprut
�y ���
hPiprut
�y!yD�B�� .
Definition 4 Let u B
�7 8 �u7X ��w �  � be a
 -GMTG and let  B
 
� ��&  � with 
R
w
and 9B
�&E

� �� E

�
� � �y!
� � �y!
�
�. Let
f and � be two ITVs with f
 j'�!B
�f
� ��ff
�
� and
�
 j'�B
��'
� ����'
�
�. Assume that y is some concatenation of all ytg and that f is some concatenation of all ffhg , aiojei  , Hil ik , and let
5 be
some reindexing such that strings
5 �y � and f are
independent. The derives relation f��

� holds
whenever there exists an index T
R
@ such that the
following two conditions are satisfied:
(i) for each j
R
uh r
� � we have
ff
� 
fs
�
B fy
E GPI6Q

� f9y
�
E GPI6Q

� 
f9y
� �
E GI6Q

�
fy
�
such that T
R
hPiprut
�f y� fy
� 
f9y
�
�, and each
�'hg is obtained from ftg by replacing each
E GPI6Q
hg
with
5 �y hg �;
(ii) for each j
R
h r
� � we have
T 
R
hiqprut
�fs
�p
ff
�
� and f
 j� B �
 j'�.
We generalize the �

relation to �

and �o`

in
the usual way, to represent derivations.
We can now introduce the notion of generated
language (or generated relation). A start link
of a  -GMTG is a  -dimensional link where at
least one component is
� G
�Q
�,
 the start symbol, and the rest of the components are
��. Thus,
there are !
#"
 start links. The language
generated by a  -GMTG u is $
�u �B
D
f&% (
f(')� `

f % � f&' a start link� f %
 j'�B
��orf %
 j'�B
�10
� with
0

R
7 `
X �i ji  V . Each ITV in
$
�u � is called a multitext. For every  -GMTG u ,
$
�u � can be partitioned into !
 "
 subsets, each
containing multitexts derived from a different start
link. These subsets are disjoint, since every nonempty tuple of a start link is eventually rewritten as
a string, either empty or not.5
A start production is a production whose LHS
is a start link. A GMTG writer can choose the combinations of components in which the grammar can
generate, by including start productions with the desired combinations of active components. If a grammar contains no start productions with a certain
combination of active components, then the corresponding subset of $
�u � will be empty. Allowing a single GMTG u to generate multitexts with
5
We are assuming that there are no useless nonterminals.
some empty tuples corresponds to modeling relations of different dimensionalities. This capability
enables a synchronous grammar to govern lowerdimensional sublanguages/translations. For example, an English/Italian GMTG can include Production (9), an English CFG, and an Italian CFG. A
single GMTG can then govern both translingual
and monolingual information in applications. Furthermore, this capability simplifies the normalization procedure described in Section 6. Otherwise,
this procedure would require exceptions to be made
when eliminating epsilons from start productions.
4 Generative Capacity
In this section we compare the generative capacity of GMTG with that of mildly context-sensitive
grammars. We focus on LCFRS, using the notational variant introduced by Rambow and Satta
(1999), briefly summarized below. Throughout this
section, strings
0vR
7a`
X and vectors of the form
 ��10
�� will be identified. For lack of space, some
proofs are only sketched, or entirely omitted when
relatively intuitive: Melamed et al. (2004) provide
more details.
Let 7YX be some terminal alphabet. A function
6
has rank 2�od if it is defined on
�7 `
X �  
43
�7 `
X �  65
3

3
�7a`
X �  87
, for integers
5  , gi jei92 . Also,
6 has fan-out
5   if its range is a subset of
�7�`
X �  
.
Let @BA , C9tg ,  iEDki
5 ,  i~jaiF2 and  ixlmi
5  , be string-valued variables. Function
6 is linear
regular if it is defined by an equation of the form
6 �HG
C
� � ��HC
� 

I
�� G
CQP
� � �HC P  87
I
�
B
G
@
� ��H@  
I
(24)
where
G
@
� ��H@  
I
represents some grouping into
5
strings of all and only the variables appearing in the
left-hand side, possibly with some additional terminal symbols. (Symbols  , q and �

are overloaded
below.)
Definition 5 A Linear Context-Free Rewriting System (LCFRS) is a quadruple
u B
�7 8 �u7YX ��w �  � where 7 8 , 7YX and
 are
as in GMTGs, every
E R
7 8 is associated
with an integer q
�&E
�|  with q
� �SB  ,
and w is a finite set of productions of the form
E
� 6 �SR
� � R
� �� RUT
GWVuQ �, where 
�76 �  d ,
E
� R

R
798 , Cixji 
�76 � and where
6 is a linear
regular function having rank 
�76 � and fan-out
q
�&E
�, defined on
�7g`
X �6X
GY

Q
3

3
�7a`
X � X
GYQ`a b6c&Q
.
For every
E R
78 and d
R �7a`
X �6X
GWe Q
, we write
E
�

d if
(i)
E
� 6 �� R
w and
6 ��B�d ; or else
(ii)
E
� 6 �SR
� �� R T
G VuQ � R
w ,
R
 �

d
R
�7g`
X �6X
GY

Q
for every  i j i 
�76 �, and
6 �d
� ��d
T
GWVuQ � B d .
The language generated by u is defined as $
�u �B
D 0
(  �
 �10
�� 0 R
7H`
X V . Let 
R
w ,
~B
E
� 6 �SR
� � R
� �� R T
GWVuQ �. The rank of 
and u are, respectively, 
� �aB 
�76 � and 
�u �B
C�a
� �. The fan-out of  and u are, respectively, q
� �B q
�&E
� and q
�u �BxC � q
� �.
The proof of the following theorem is relatively
intuitive and therefore omitted.
Theorem 1 For any LCFRS u , there exists some
1-GMTG u y with 
�uWyD�xB 
�u � and q
�u yD�xB
q
�u � such that $
�u yD� B $
�u �.
Next, we show that the generative capacity of
GMTG does not exceed that of LCFRS. In order
to compare string tuples with bare strings, we introduce two special functions ranging over multitexts. Assume two fresh symbols
�
��� 
R �79X d
7 8 �. For a multitext f we write �p
�f � B
f9y , where fy
 j'� B
�� � if f
 j'� B
�� and
f9y
 j'� B f
 j� otherwise, vi jsi  . For
a multitext
 ��10
� �� �10
� �� � �10
 �� with no empty
tuple, we write �����qr
�  ��10
� �� �10
� ��� �10
 ��!� B
0
�
� 0
�
�

� 0
 . We extend both functions to
sets of multitexts in the obvious way: ����r
�$ � B
D
����r
�
� ( 3R
$V and �p
�$ �B
D
�p
�
� ( R
$eV .
In a  -GMTG, a production with
2 active components, i
2 i  , is said to be
2 -active. A
 -GMTG whose start productions are all  -active
is called properly synchronous.
Lemma 1 For any properly synchronous  -GMTG
u , there exists some LCFRS u y with 
�uWyD�pBx
�u �
and q
�uWy7� Bq
�u � such that $
�u yD�B����qr
�$
�u � �.
Outline of the proof. We set u y B
�7 y
8 �7YX �w y �
  �$�, where 7 y
8 B
D   �T� (9
R
w �T
R
hiqprut
�u �Vd
D   �0V , hPiprut
�u � is the set of all indexes appearing
in the productions of u , and wgy is constructed as
follows. Let  �9y
R
w with B
 
� ��&  �,
y B
 y
� ��&y �,  B
�&E

� �� E
  � �
�y 
� � �y!
�
�, and 9y B
�SR

� � � R
  � �
�z 
� ��z 



�. Assume that  can rewrite the righthand side of y , that is
 ��z
� � ��z
��


�� � �z 
� � �z 



��
�
  ���
� � ����
��
�� � ��
� ����
#
��
Then there must be at least one index T such that for
each j
R
h r
� �,
�z
� ��z 



� contains exactly
 occurrences of T .
Let y  B y
� �!
y
��
y
� �!
y
�
. Also let
hPiprut
�y  �B
D
T
� ��T
T
G  Q V and let q
�T'� be the
number of occurrences of T appearing in y  . We
define an alphabet
# |B
D
C9hg (  i j i

� ��xi l i q
�T#�V . For each j and l with
 i jei  , j
R
h r
� � and ~i l i  ,
we define a string D
� �j ��l � over
# nd7X as follows. Let y hgnB
%
�
%
�3
%
, each
%wR
7 b . Then
D
� �j ��l �vB
% y
�
% y
� 
% y

, where
 % y

B
%
in case
%gR
7YX ; and
 % y

B C I ! in case
%eR
A
�7 8 �, where T is
the index of
%
and the indicated occurrence
of
%
is the " -th occurrence of such symbol
appearing from left to right in string y  .
Next, for every possible  , y , and T as above, we
add to wy a production
 I B
  y �T � � 6 �   �T
� �� �   �T
T
G  Q �$��
where
6 �HG
C
� � ��HC
�X
GPI

Q
I
�� G
C
T
G  Q
� ��HC
T
G  Q
X
GI `Ha #�c Q
I
�
B
G
D
� �B���B��D
� �  ��q � I
(each D
� �j ��l � above satisfies j
R
quh r
� �). Note
that
6 is a function with rank 
� � and fan-out


��
�  B q
� �. Thus we have 
� I � B 
� �
and q
� I � B q
� �. Without loss of generality,
we assume that u contains only one production
with
 appearing on the left-hand side, having the
form  ' B
 �� ��� � �� �  ��&E
� �� � �&E
� ��.
To complete the construction of wgy , we then
add a last production
  � � 6 �   ' � �$� where
6 �HG
C
� � �HC
�� � �HC
�
I
�}B
G
C
� �
�
C
��
�

�
C
�
I
.
We claim that, for each  ,  y and T as above
 ��&E
�� � �� E
���
��� �&E
�
� �� E
�
�
��
�}`
  ��%$
� � �� $
��
��� �%$

� �� $

 
��
iff
 9y$�T���


G%$
� � �� $
��
� $
� � � � 0

�
I
. The
lemma follows from this claim.
The proof of the next lemma is relatively intuitive
and therefore omitted.
Lemma 2 For any  -GMTG u , there exists a properly synchronous  -GMTG u y such that 
�u yD�CB

�u �, q
�uWy7�B C
D
q
�u �� rV , and $
�uWyD�xB
�p
�$
�u � �.
Combining Lemmas 1 and 2, we have
Theorem 2 For any  -GMTG u , there exists
some LCFRS u y with 
�uWyD� B 
�u � and
q
�uWy7� B C
D
q
�u ��  V such that $
�u yD�SB
����r
��p
�$
�u � � �.
5 Weak Language Preservation Property
GMTGs have the weak language preservation property, which is one of the defining requirements of
synchronous rewriting systems (Rambow and Satta,
1996). Informally stated, the generative capacity of
the class of all component grammars of a GMTG
exactly corresponds to the class of all projected languages. In other words, the interaction among different grammar components in the rewriting process
of GMTG does not increase the generative power
beyond the above mentioned class. The next result
states this property more formally.
Let u be a  -GMTG with production set w .
For Si j i  , the j -th component grammar of u , written �� ��
� �u �j �, is the 1-GMTG
with productions w3~B
D
9 (  
� � �& � R
w �  B
�� � ��V . Similarly, the j -th
projected language of $
�u � is �� ��
� �$
�u ��j � B
D 0
 (  ��10
� �� � �10
 �� R
$
�u �� �10
� B
��V . In general $
��� ��
� �u �j � � B �� ��
� �$
�u ��j �,
because component grammars �� ��
� �u �j � interact with each other in the rewriting process of
u . To give a simple example, consider the 2GMTG u with productions
 �� �� � �� �  ��!" �� �!" ��,
 �� �� � ��1�  ��!sEHG
�Q
�� �! pG
�Q
�� and
 ��&E
�� � �� �
 �� G
�Q
�� � G
�Q & ��. Then $
�u � B
D  ��!��
�� �!�� &��
�� (
 dfV , and thus �� ��
� �$
�u ���! ��B
D�� &��
(  
dfV . On the other hand, $
��� ��
� �u ��! � ��B
D� & !
(
 � " dfV . Let 
�LCFRS� be the class of all languages generated by LCFRSs. Also let   G

Q and
  GQ be the classes of languages $
��� ��
� �u � 2 � � and
�� ��
� �$
�u �� 2 � �, respectively, for every |  , every  -GMTG u and every
2 with i
2 i  .
Theorem 3   G

Q B 
�$ 
 � and   G!fQ B

�$"#
 �.
Proof. The $ cases directly follow from Theorem 1.
Let u be some  -GMTG and let
2 be an integer
such that  i
2 i  . It is not difficult to see that
����r
��p
�$
��� ��
� �u � 2 � � � �B�$
��� ��
� �u � 2 � �. Hence
$
��� ��
� �u � 2 � � can be generated by some LCFRS, by
Theorem 2.
We now define a LCFRS u y such that
$
�u y�B �� ��
� ��qp
�$
�u � �� 2 � �. Assume u y y}B
�798 �u7 X ��w �  � is a properly synchronous  -GMTG
generating �p
�$
�u � � (Lemma 2). Let uy�B
�7 y
8 �u7YX ��w y �   �$�, where 7 y
8 and w y are constructed
from u y y almost as in the proof of Lemma 1.
The only difference is in the definition of strings
D
� �j ��l � and the production rewriting
  �, specified as follows (we use the same notation as in the
proof of Lemma 1). D
� �j ��l �vB
% y
�
% y
� 
% y

, where
for each % : (i)
% y

B
%
if
%eR
7X and j B
2 ;
(ii)
% y

B
" if
% R
7X and j B
2 ; (iii)
% y

B C I !
if
%{R
A
�7 8 �, with T , " as in the original proof.
Finally, the production rewriting
  � has the form
  � � 6 �  (' � �$�, where
6 �HG
C
� � �HC
�� ��HC
�
I
�aB
G
C
� � C
��3
C
�
I
. To conclude the proof, note that
�� ��
� �$
�u �� 2 � � and �� ��
� ��p
�$
�u � �� 2 � � can differ
only with respect to string � . The theorem then follows from the fact that LCFRS is closed under intersection with regular languages (Weir, 1988).
6 Generalized Chomsky Normal Form
Certain kinds of text analysis require a grammar in a
convenient normal form. The prototypical example
for CFG is Chomsky Normal Form (CNF), which is
required for CKY-style parsing. A  -GMTG is in
Generalized Chomsky Normal Form (GCNF) if it
has no useless links or useless terminals, and every
production is in one of two forms:
(i) A nonterminal production has rank = 2 and
no terminals or
" 's on the RHS.
(ii) A terminal production has exactly one component of the form
E
� , where
ExR
7 8 and
R
7YX . The other components are inactive.
The algorithm to convert a GMTG to GCNF has
the following steps: (1) add a new start-symbol (2)
isolate terminals, (3) binarize productions, (4) remove
" 's, (5) eliminate useless links and terminals,
and (6) eliminate unit productions. The steps are
generalizations of those presented by Hopcroft et al.
(2001) to the multidimensional case with discontinuities. The ordering of these steps is important, as
some steps can restore conditions that others eliminate. Traditionally, the terminal isolation and binarization steps came last, but the alternative order
reduces the number of productions that can be created during
" -elimination. Steps (1), (2), (5) and (6)
are the same for CFG and GMTG, except that the
notion of nonterminal in CFG is replaced with links
in GMTG. Some complications arise, however, in
the generalization of steps (3) and (4).
6.1 Step 3: Binarize
The third step of converting to GCNF is binarization
of the productions, making the rank of the grammar
two. For 2�od and
5   , we write D-GMTG
G P Q
  to
represent the class of all  -GMTGs with rank 2 and
fan-out
5 . A CFG can always be binarized into another CFG: two adjacent nonterminals are replaced
with a single nonterminal that yields them. In contrast, it can be impossible to binarize a  -GMTG
G P Q
 
into an equivalent  -GMTG�  . From results presented by Rambow and Satta (1999) it follows that,
 
(S)
(S)�
�
  �N�PatV�wentP@homeAAearly�
�P@damoyN�PatAAranoV�pashol��
Pat went home early
damoy
Pat
rano
pashol
Figure 1: A production that requires an increased
fan-out to binarize, and its 2D illustration.
for every fan-out
5  ! and rank 2 �  , there
are some index orderings that can be generated by
 -GMTG
G P Q
  but not  -GMTG
G P
 �Q
  . The distinguishing characteristic of such index orderings is
apparent in Figure 1, which shows a production in
a grammar with fan-out two, and a graph that illustrates which nonterminals are coindexed. No two
nonterminals are adjacent in both components, so
replacing any two nonterminals with a single nonterminal causes a discontinuity. Increasing the fanout of the grammar allows a single nonterminal to
rewrite as non-adjacent nonterminals in the same
string. Increasing the fan-out can be necessary even
for binarizing a 1-GMTG production such as:
 ��S,S�� �  ��N� V� P@ AA �P@ N�AA V� �� (25)
To binarize, we nondeterministically split each
nonterminal production & of rank 2  ! into two
nonterminal productions 
� and 
� of rank

2 , but
possibly with higher fan-out. Since this algorithm
replaces 2 with two productions that have rank

2 ,
recursively applying the algorithm to productions of
rank greater than two will reduce the rank of the
grammar to two. The algorithm follows:
(i) Nondeterministically chose  links to be removed from   and replaced with a single link
to make 
�, where !}i
 i 2
"
 . We call
these links the m-links.
(ii) Create a new ITV f . Two nonterminals are
neighbors if they are adjacent in the same
string in a production RHS. For each set of mlink neighbors in component
2 in   , place that
set of neighbors into the
2 'th component of f
in the order in which they appeared in   , so
that each set of neighbors becomes a different
string, for i
2 i  .
(iii) Create a new unique nonterminal, say
R
, and
replace each set of neighbors in production  
with
R
, to create 
� . The production 
� is
 R
�� R
� � f
For example, binarization of the productions for the
English/Russian multitext [(Pat went home early),
(damoy Pat rano pashol)]6 in Figure 1 requires that
we increase the fan-out of the language to three. The
binarized productions are as follows:
  �S�
�S��
�
  �N�PatVP� �
�VP� N�PatVP� ��
(26)
  �VP�
�VP�VP��
�
  �V� A�early�
�V� � A�ranoV� ��
(27)
  �V�
�V� V���
�
  �V�wentP�home�
�P�damoy �V�pashol ���
(28)
6.2 Step 4: Eliminate
" 's
Grammars in GCNF cannot have
" 's in their
productions. Thus, GCNF is a more restrictive
normal form than those used by Wu (1997) and
Melamed (2003). The absence of
" 's simplifies
parsers for GMTG (Melamed, 2004). Given a
GMTG u with
" in some productions, we give
the construction of a weakly equivalent grammar uWy without any
" 's. First, determine all
nullable links and associated strings in u . A
link � B
 ��&E
� �� E
� ��� �&E
 �� E
 ��
is nullable if � `
� f , where f B
 ��y
� � ��y
��
��� �y
� ��y
�
�� is an
ITV where at least one yhg is
" . We say the link
� is nullable and the string at address
�!2 �� � in
� is nullable. For each nullable link, we create
!
�
versions of the link, where  is the number of
nullable strings of that link. There is one version for
each of the possible combinations of the nullable
strings being present or absent. The version of the
link with all strings present is its original version.
Each non-original version of the link (except in the
case of start links) gets a unique subscript, which is
applied to all the nonterminals in the link, so that
each link is unique in the grammar. We construct
a new grammar u y whose set of productions w y
is determined as follows: for each production, we
identify the nullable links on the RHS and replace
them with each combination of the non-original
versions found earlier. If a string is left empty
during this process, that string is removed from the
RHS and the fan-out of the production component
is reduced by one. The link on the LHS is replaced
with its appropriate matching non-original link.
There is one exception to the replacements. If a
production consists of all nullable strings, do not
include this case. Lastly, we remove all strings on
the RHS of productions that have
" 's, and reduce
the fan-out of the productions accordingly. Once
6
The Russian is topicalized but grammatically correct.
again, we replace the LHS link with the appropriate
version.
Consider the example grammar:
 �� �� � ���  ��&E
� R
� E
� �� �SR
� E
� �� (29)
 ��&E
� E
�� �&E
�� �  ��! � R
� �� �SR
� �� (30)
 ��SR
�� �SR
���  ��'& �� �!" �� (31)
 ��SR
�� �SR
���  ��'& �� �'& & �� (32)
We first identify which links are nullable. In this
case
 ��&E
� E
�� �&E
�� and
 ��SR
�� �SR
�� are nullable so we
create a new version of both links:
 ��&E
� � E
� �� ���
and
 ��SR
� �� ���. We then alter the productions. Production (31) gets replaced by (40). A new production based on (30) is Production (38). Lastly, Production (29) has two nullable strings on the RHS,
so it gets altered to add three new productions, (34),
(35) and (36). The altered set of productions are the
following:
 �� �� � �� �  ��&E
� R
� E
� �� �SR
� E
� �� (33)
 �� �� � �� �  ��&E
� R
��
E
� �� �&E
� �� (34)
 �� �� � �� �  ��&E
��
R
� E
�� �� �SR
� �� (35)
 �� �� ��� �  ��&E
��
R
��
E
�� �� ��� (36)
�&E
� E
�� �&E
�� �  ��! � R
� �� �SR
� � (37)
 ��&E
� � E
� �� ����  ��! � R
�� �� ��� (38)
 ��SR
�� �SR
���  ��'& �� �'& & �� (39)
 ��SR
� �� ����  ��'& �� ��� (40)
Melamed et al. (2004) give more details about
conversion to GCNF, as well as the full proof of our
final theorem:
Theorem 4 For each GMTG u there exists a
GMTG u y in GCNF generating the same set of multitexts as u but with each
�!" � component in a multitext replaced by
��.
7 Conclusions
Generalized Multitext Grammar is a convenient and
intuitive model of parallel text. In this paper, we
have presented some formal properties of GMTG,
including proofs that the generative capacity of
GMTG is comparable to ordinary LCFRS, and that
GMTG has the weak language preservation property. We also proposed a synchronous generalization of Chomsky Normal Form, laying the foundation for synchronous CKY parsing under GMTG. In
future work, we shall explore the empirical properties of GMTG, by inducing stochastic GMTGs from
real multitexts.
Acknowledgments
Thanks to Owen Rambow and the anonymous reviewers for valuable feedback. This research was
supported by an NSF CAREER Award, the DARPA
TIDES program, the Italian MIUR under project
PRIN No. 2003091149 005, and an equipment gift
from Sun Microsystems.
References
A. Aho and J. Ullman. 1969. Syntax directed translations and
the pushdown assembler. Journal of Computer and System
Sciences, 3:37�56, February.
T. Becker, A. Joshi, and O. Rambow. 1991. Long-distance
scrambling and tree adjoining grammars. In Proceedings of
the 5th Meeting of the European Chapter of the Association
for Computational Linguistics (EACL), Berlin, Germany.
E. Bertsch and M. J. Nederhof. 2001. On the complexity
of some extensions of RCG parsing. In Proceedings of
the 7th International Workshop on Parsing Technologies
(IWPT), pages 66�77, Beijing, China.
M. Dras and T. Bleam. 2000. How problematic are clitics for
S-TAG translation? In Proceedings of the 5th International
Workshop on Tree Adjoining Grammars and Related Formalisms (TAG+5), Paris, France.
J. Hopcroft, R. Motwani, and J. Ullman. 2001. Introduction to
Automota Theory, Languages and Computation. AddisonWesley, USA.
I. Dan Melamed, G. Satta, and B. Wellington. 2004. Generalized multitext grammars. Technical Report 04-003, NYU
Proteus Project. http://nlp.cs.nyu.edu/pubs/.
I. Dan Melamed. 2003. Multitext grammars and synchronous
parsers. In Proceedings of the Human Language Technology
Conference and the North American Association for Computational Linguistics (HLT-NAACL), pages 158�165, Edmonton, Canada.
I. Dan Melamed. 2004. Statistical machine translation by parsing. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL), Barcelona,
Spain.
O. Rambow and G. Satta. 1996. Synchronous models of language. In Proceedings of the 34th Annual Meeting of the Association for Computational Linguistics (ACL), Santa Cruz,
USA.
O. Rambow and G. Satta. 1999. Independent parallelism in
finite copying parallel rewriting systems. Theoretical Computer Science, 223:87�120, July.
O. Rambow. 1995. Formal and Computational Aspects of Natural Language Syntax. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA.
S. Shieber. 1994. Restricting the weak-generative capactiy of
synchronous tree-adjoining grammars. Computational Intelligence, 10(4):371�386.
D. J. Weir. 1988. Characterizing Mildly Context-Sensitive
Grammar Formalisms. Ph.D. thesis, Department of Computer and Information Science, University of Pennsylvania.
D. Wu. 1997. Stochastic inversion transduction grammars and
bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377�404, September.
D. H. Younger. 1967. Recognition and parsing of context-free
languages in time  
�
. Information and Control, 10(2):189�
208, February.


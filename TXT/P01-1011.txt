Underspecified Beta Reduction
Manuel Bodirsky
Katrin Erk
Joachim Niehren
Programming Systems Lab
Saarland University
D-66041 Saarbr�
ucken, Germany
{bodirsky|erk|niehren}@ps.uni-sb.de
Alexander Koller
Department of Computational Linguistics
Saarland University
D-66041 Saarbr�
ucken, Germany
koller@coli.uni-sb.de
Abstract
For ambiguous sentences, traditional
semantics construction produces large
numbers of higher-order formulas,
which must then be
 
-reduced individually. Underspecified versions can produce compact descriptions of all readings, but it is not known how to perform
 
-reduction on these descriptions. We
show how to do this using
 
-reduction
constraints in the constraint language
for � -structures (CLLS).
1 Introduction
Traditional approaches to semantics construction
(Montague, 1974; Cooper, 1983) employ formulas of higher-order logic to derive semantic representations compositionally; then
 
-reduction is
applied to simplify these representations. When
the input sentence is ambiguous, these approaches
require all readings to be enumerated and
 
reduced individually. For large numbers of readings, this is both inefficient and unelegant.
Existing underspecification approaches (Reyle,
1993; van Deemter and Peters, 1996; Pinkal,
1996; Bos, 1996) provide a partial solution to this
problem. They delay the enumeration of the readings and represent them all at once in a single,
compact description. An underspecification formalism that is particularly well suited for describing higher-order formulas is the Constraint Language for Lambda Structures, CLLS (Egg et al.,
2001; Erk et al., 2001). CLLS descriptions can
be derived compositionally and have been used
to deal with a rich class of linguistic phenomena
(Koller et al., 2000; Koller and Niehren, 2000).
They are based on dominance constraints (Marcus et al., 1983; Rambow et al., 1995) and extend
them with parallelism (Erk and Niehren, 2000)
and binding constraints.
However, lifting
 
-reduction to an operation on
underspecified descriptions is not trivial, and to
our knowledge it is not known how this can be
done. Such an operation � which we will call underspecified
 
-reduction � would essentially
 
reduce all described formulas at once by deriving a description of the reduced formulas. In this
paper, we show how underspecified
 
-reductions
can be performed in the framework of CLLS.
Our approach extends the work presented in
(Bodirsky et al., 2001), which defines
 
-reduction
constraints and shows how to obtain a complete
solution procedure by reducing them to parallelism constraints in CLLS. The problem with
this previous work is that it is often necessary to
perform local disambiguations. Here we add a
new mechanism which, for a large class of descriptions, permits us to perform underspecified
 
-reduction steps without disambiguating, and is
still complete for the general problem.
Plan. We start with a few examples to show
what underspecified
 
-reduction should do, and
why it is not trivial. We then introduce CLLS
and
 
-reduction constraints. In the core of the
paper we present a procedure for underspecified
 
-reduction and apply it to illustrative examples.
2 Examples
In this section, we show what underspecified
 
reduction should do, and why the task is nontrivial. Consider first the ambiguous sentence Every
student didn't pay attention. In first-order logic,
the two readings can be represented as
�
� ���
�
�
�
�  �
�
 �  �
� ���
�
 � �   �
!
"$#
%'&
%'(
%')
%10
%2#
%'3
%54
%76
�
�
�
�8  �
�
� ���
�
 � � 9  �
 �
!
"@3
ACB
AC&
A (
AC6
AC)
AD0
�
�
�
�  �
�
 � �   �E
!
"@(
Figure 1: Underspecified
 
-reduction steps for `Every student did not pay attention'
�
�
F HG I �
� ���
�
 � � 9  �
!
"P&
QR&
Figure 2: Description of `Every student did not
pay attention'
�'SUT �8 S � ! T  � � 9 SWVV
! TX�'SUT �8 S �  � � 9 SWVV
A classical compositional semantics construction
first derives these two readings in the form of two
HOL-formulas:
T8F HG I � V
�
SYT !  �`a�  S1V
! TT8F HG b �8 V
�
SYT  �`a�  S1VV
where
F HG I
is an abbreviation for the term
F G Idc
�feg�'h
TX�'SUT
e
S �
h
S1VV
An underspecified description of both readings is
shown in Figure 2. For now, notice that the graph
has all the symbols of the two HOL formulas as
node labels, that variable binding is indicated by
dashed arrows, and that there are dotted lines indicating an "outscopes" relation; we will fill in the
details in Section 3.
Now we want to reduce the description in Figure 2 as far as possible. The first
 
-reduction step,
with the redex at
QR&
is straightforward. Even
though the description is underspecified, the reducing part is a completely known � -term. The
result is shown on the left-hand side of Figure 1.
Here we have just one redex, starting at
% &
, which
binds a single variable. The next reduction step
is less obvious: The ! operator could either belong to the context (the part between
"d#
and
%7&
)
�
� ���
i
�
p  �
q
! i
�
p
q
!
Q
% r
s
Figure 3: Problems with rewriting of descriptions
or to the argument (below
%54
). Still, it is not difficult to give a correct description of the result:
it is shown in the middle of Fig. 1. For the final
step, which takes us to the rightmost description,
the redex starts at
ADB
. Note that now the ! might
be part of the body or part of the context of this
redex. The end result is precisely a description of
the two readings as first-order formulas.
So far, the problem does not look too difficult.
Twice, we did not know what exactly the parts of
the redex were, but it was still easy to derive correct descriptions of the reducts. But this is not
always the case. Consider Figure 3, an abstract
but simple example. In the left description, there
are two possible positions for the ! : above
Q
or
below
%
. Proceeding na�
ively as above, we arrive
at the right-hand description in Fig. 3. But this description is also satisfied by the term
i T ! TtpT q VVV
,
which cannot be obtained by reducing any of the
terms described on the left-hand side. More generally, the na�
ive "graph rewriting" approach is
unsound; the resulting descriptions can have too
many readings. Similar problems arise in (more
complicated) examples from semantics, such as
the coordination in Fig. 8.
The underspecified
 
-reduction operation we
propose here does not rewrite descriptions. Instead, we describe the result of the step using a
"
 
-reduction constraint" that ensures that the reduced terms are captured correctly. Then we use a
saturation calculus to make the description more
explicit.
3 Tree descriptions in CLLS
In this section, we briefly recall the definition of
the constraint language for � -structures (CLLS).
A more thorough and complete introduction can
be found in (Egg et al., 2001).
We assume a signature u
c v i7w8x5wyyy
of
function symbols, each equipped with an arity
�T i V
. A tree  consists of a finite set of
nodes Y , each of which is labeled by a symbol 
T

V
u . Each node  has a sequence of
children C
wyyyUw
1 where 
cd�8T
e
T

VV
is the arity of the label of  . A single node f , the
root of  , is not the child of any other node.
3.1 Lambda structures
The idea behind � -structures is that a � -term can
be considered as a pair of a tree which represents
the structure of the term and a binding function
encoding variable binding. We assume u contains
symbols  �E
(arity 0, for variables),
� �g�
(arity 1,
for abstraction),
�
(arity 2, for application), and
analogous labels for the logical connectives.
Definition 1. A � -structure h is a pair
T

w
�
V
of
a tree  and a binding function � that maps every
node  with label  �
to a node with label
� ���
,
�
,
or i dominating  .
� ���
�
i  �
The binding function � explicitly
maps nodes representing variables to
the nodes representing their binders.
When we draw � -structures, we represent the binding function using dashed arrows,
as in the picture to the right, which represents the
� -term �
S yji TkSWV
.
A � -structure corresponds uniquely to a closed
� -term modulo l -renaming. We will freely
consider � -structures as first-order model structures with domain  . This structure defines
the following relations. The labeling relation
nm
i T

# wyyy2w
5o
V
holds in  if 
T

Vpc i
and
fq
c
1r for all tsursu . The dominance relation Wvxw`1y holds iff there is a path 1y y such that
W y y
c
 y . Inequality z
c
is simply inequality of
nodes; disjointness 2{P1y holds iff neither Wvxw`1y
nor  y v w  .
3.2 Basic constraints
Now we define the constraint language for � structures (CLLS) to talk about these relations.
Q w % w A
are variables that will denote nodes of a
� -structure.
| mIm
c Q
v w
%~}aQ
z
c %~}aQ
{
%~} |tt| y
} Q
m
i T Q# wyyy2w Q
o
V Tt�T i VCc

V
}
�
T Q Vc %}
�W
# T QR& Vcdv Q# wyyyw Q
o

A constraint | is a conjunction of literals (for
dominance, labeling, etc). We use the abbreviations
Q
vx
%
for
Q
vxw
%  Q
z
c %
and
Q c
%
for
Q
v w
%  %
v w
Q
. The � -binding literal
�
T Q Vc %
expresses that
%
denotes a node which
the binding function maps to
Q
. The inverse
� -binding literal �W
# T QR& Vcdv Q# wyyy2w Q
o

states
that
Q # wyyy2w Q
o denote the entire set of variable nodes bound by
QR&
. A pair
T
h
w V
of a � structure h and a variable assignment

satisfies a
� -structure iff it satisfies each literal, in the obvious way.
� ���
 �E  �
Q
Q # Q 3
Figure 4: The constraint graph of
� 
# T Q Vcgv Q# w QR3   Q
vxw
Q#  Q
vxw
QR3
We draw constraints as graphs (Fig. 4) in which
nodes represent variables. Labels and solid lines
indicate labeling literals, while dotted lines represent dominance. Dashed arrows indicate the binding relation; disjointness and inequality literals
are not represented. The informal diagrams from
Section 2 can thus be read as constraint graphs,
which gives them a precise formal meaning.
3.3 Segments and Correspondences
Finally, we define segments of � -structures and
correspondences between segments. This allows
us to define parallelism and
 
-reduction constraints.
A segment is a contiguous part of a � -structure
that is delineated by several nodes of the structure.
Intuitively, it is a tree from which some subtrees
have been cut out, leaving behind holes.
Definition 2 (Segments). A segment l of a � structure
T

w
�
V
is a tuple 
&t

# yyy2w
5o of nodes
in  such that 
&
v w 5q and 5qt{P hold in  for
srz
c
s . The root 
T
l
V
is 
&
, and
5T
l
Vc

# wyyy2w
fo is its (possibly empty) sequence of holes. The set 
T
l
V
of nodes of l is

T
l
Vcdv
Y
}

T
l
V
vxw`
w
and not  q vxn
for all srs

To exempt the holes of the segment, we define
 
T
l
Vc

T
l
V'�T
l
V
. If
'�T
l
V
is a singleton
sequence then we write
2T
l
V
for the unique hole
of l , i.e. the unique node with
T
l
V

5T
l
V
.
For instance, l
c

#

3 w

(
is a segment in
Fig. 5; its root is 
#
, its holes are 
3
and 
(
, and
it contains the nodes 
T
l
Vcv

# w

6 w

3 w

( 
.
Two tree segments l
w 
overlap properly iff
x
T
l
V
x
T   V
z
c
. The syntactic equivalent
of a segment is a segment term
QR&Q# wyyy Q
o .
We use the letters  
w��w��Pw
 for them and extend

T
 
V
,
'�T
 
V
, and
2T
 
V
correspondingly.
A correspondence function is intuitively an isomorphism between segments, mapping holes to
holes and roots to roots and respecting the structures of the trees:
Definition 3. A correspondence function between the segments l
w 
is a bijective mapping
� m�
T
l
V � 
T   V
such that � maps the r -th hole
of l to the r -th hole of
 
for each r , and for every
x
T
l
V
and every label
i
,
nm
i T
C
wyyyw
1
Vn� � T

V
m
i T � T
C
V wyyy � T
1
VV y
There is at most one correspondence function
between any two given segments. The correspondence literal co
T �@w

V`T Q Vc %
expresses that a
correspondence function � between the segments
denoted by
�
and  exists, that
Q
and
%
denote
nodes within these segment, and that these nodes
are related by � .
Together, these constructs allow us to define
parallelism, which was originally introduced for
the analysis of ellipsis (Egg et al., 2001). The parallelism relation l�
 
holds iff there is a correspondence function between l and
 
that satisfies some natural conditions on � -binding which
we cannot go into here. To model parallelism in
the presence of global � -binders relating multiple
parallel segments, Bodirsky et al. (2001) generalize parallelism to group parallelism. Group parallelism
T
l
# wyyy2w
l2o
V
�
T   # wyyy2w 
o
V
is entailed
� ���
x
i
�
� �g�
�
 �  �
q
i
�
 � q

&
1y
&

#

6
 y
#

3

4

(
1y
(
Figure 5:
i TT
�
S y�� TkSWVV`T q VV ��� i T � T q VV
by the conjunction  o
qb
#
l q �
 
q of ordinary parallelisms, but imposes slightly weaker restrictions
on � -binding. By way of example, consider the � structure in Fig. 5, where
T

& 

# w

3a

4 w

(  V
�
T
1y
& 
1y
# w
1y
# 
1y
4 w
1y
4  V
holds.
On the syntactic side, CLLS provides
group parallelism literals
T
 
# wyyy2w
  o
V
�
T � # wyyy�w�
o
V
to talk about (group) parallelism.
4 Beta reduction constraints
Correspondences are also used in the definition of
 
-reduction constraints (Bodirsky et al., 2001).
A
 
-reduction constraint describes a single
 
reduction step between two � -terms; it enforces
correct reduction even if the two terms are only
partially known.
Standard
 
-reduction has the form
� TT
�
S y�� V
 
V ��� � T ��� S 
 ��
V�S
free for  
y
The reducing � -term consists of context
�
which
contains a redex
T
�
S y�� V
  . The redex itself is an
occurrence of an application of a � -abstraction
�
S y��
with body
�
to argument   .
 
-reduction
then replaces all occurrences of the bound variable
S
in the body by the argument while preserving the context.
We can partition both redex and reduct into argument, body, and context segments. Consider
Fig. 5. The � -structure contains the reducing � term
i TT
�
S y�� TkS1VV`T q VV
starting at 
&
. The reduced
term can be found at  y
&
. Writing �
w
� y for the
context,
 Dw 
y for the body and l
w
l2y for the argument tree segments of the reducing and the reduced term, respectively, we find
�
c

&�

#   c

3�

4
l
c

(�
�'y
c
1y
& 
1y
#  
y
c
1y
# 
1y
(
l2y
c
1y
( 
Because we have both the reducing term and the
reduced term as parts of the same � -structure, we
can express the fact that the structure below  y
&
can be obtained by
 
-reducing the structure below 
&
by requiring that l corresponds to l2y ,
 
to
 
y , and � to � y , again modulo binding. This is
indeed true in the given � -structure, as we have
seen above.
More generally, we define the
 
-reduction relation
T
�
w Dw
l
V
�
� T
� y
w 
y
w
l y
# wyyyw
l yo
V
for a body
 
with  holes (for the variables bound
in the redex). The
 
-reduction relation holds iff
two conditions are met:
T
�
w Dw
l
V
must form a reducing term, and the structural equalities that we
have noted above must hold between the tree segments. The latter can be stated by the following
group parallelism relation, which also represents
the correct binding behaviour:
T
�
w Dw
l
wyyynw
l
V
�
T
�7y
w 
y
w
l2y
# wyyy�w
l2yo
V
Note that any � -structure satisfying this relation
must contain both the reducing and the reduced
term as substructures. Incidentally, this allows us
to accommodate for global variables in � -terms;
Fig. 5 shows this for the global variable
�
.
We now extend CLLS with
 
-reduction constraints
T �@w��w
 
V
�
� T �
y
w�
y
w
  y
# wyyy�w
  yo
V w
which are interpreted by the
 
-reduction relation.
The reduction steps in Section 2 can all be
represented correctly by
 
-reduction constraints.
Consider e.g. the first step in Fig. 1. This is represented by the constraint
T "d#%'& w %73 %'( w %'4  V
�
�
T "P3 AC& w AC& AD( w AC(  V
. The entire middle constraint in Fig. 1 is entailed by the
 
-reduction literal. If we learn in addition that e.g.
%10
vxw
%'&
,
the
 
-reduction literal will entail
A 0
vxw
A &
because
the segments must correspond. This correlation
between parallel segments is the exact same effect (quantifier parallelism) that is exploited in
the CLLS analysis of "Hirschb�
uhler sentences",
where ellipses and scope interact (Egg et al.,
2001).
 
-reduction constraints also represent the problematic example in Fig. 3 correctly. The spurious solution of the right-hand constraint does not
usb(| , X) =
if all syntactic redexes in | below
Q
are reduced then return
T | w Q V
else
pick a formula redex�
T �@w��w
 
V
in |
that is unreduced, with
Q c

T � V
in |
add
T �@w��w
 
V
�
� T �
y
w�
y
w
  y
# wyyy�w
  yo
V
to | where
�
y
w�
y
w
 �y
# wyyy2w
 �yo are new
segment terms with fresh variables
add
Q
{P
T �
y
V
to |
for all | yW solve
T | V
do usb
T | y
w

T �
y
VV
end
Figure 6: Underspecified
 
-reduction
satisfy the
 
-reduction constraint, as the bodies
would not correspond.
5 Underspecified Beta Reduction
Having introduced
 
-reduction constraints, we
now show how to process them. In this section,
we present the procedure usb, which performs a
sequence of underspecified
 
-reduction steps on
CLLS descriptions. This procedure is parameterized by another procedure solve for solving
 
reduction constraints, which we discuss in the following section.
A syntactic redex in a constraint | is a subformula of the following form:
redex�
T �@w��w
 
Vc
df
2T � V
m
� T % w

T
 
VV
 %
m
� ���dT

T � VV  � 
#
T % VCc�5T � V
A context
�
of a redex must have a unique hole
T � V
. An  -ary redex has  occurrences of the
bound variable, i.e. the length of
5T � V
is  . We
call a redex linear if 
c
 .
The algorithm �W� � is shown in Figure 6. It
starts with a constraint | and a variable
Q
, which
denotes the root of the current � -term to be reduced. (For example, for the redex in Fig. 2,
this root would be
" &
.) The procedure then selects an unreduced syntactic redex and adds a description of its reduct at a disjoint position. Then
the solve procedure is applied to resolve the
 
reduction constraint, at least partially. If it has
to disambiguate, it returns one constraint for each
reading it finds. Finally, usb is called recursively
with the new constraint and the root variable of
the new � -term.
Intuitively, the solve procedure adds entailed
literals to | , making the new
 
-reduction literal
more explicit. When presented with the left-hand
constraint in Fig. 1 and the root variable
"d#
, usb
will add a
 
-reduction constraint for the redex at
%�#
; then solve will derive the middle constraint.
Finally, usb will call itself recursively with the
new root variable
"P3
and try to resolve the redex
at
AD(
, etc. The partial solving steps do essentially
the same as the na�
ive graph rewriting approach
in this case; but the new algorithm will behave
differently on problematic constraints as in Fig. 3.
6 A single reduction step
In this section we present a procedure solve for
solving
 
-reduction constraints. We go through
several examples to illustrate how it works. We
have to omit some details for lack of space; they
can be found in (Bodirsky et al., 2001).
The aim of the procedure is to make explicit
information that is implicit in
 
-reduction constraints: it introduces new corresponding variables and copies constraints from the reducing
term to the reduced term.
We build upon the solver for
 
-reduction constraints from (Bodirsky et al., 2001). This solver
is complete, i.e. it can enumerate all solutions of
a constraint; but it disambiguates a lot, which we
want to avoid in underspecified
 
-reduction. We
obtain an alternative procedure solve by disabling all rules which disambiguate and adding
some new non-disambiguating rules. This allows us to perform a complete underspecified
 
reduction for many examples from underspecified
semantics without disambiguating at all. In those
cases where the new rules alone are not sufficient,
we can still fall back on the complete solver.
6.1 Saturation
Our constraint solver is based on saturation with
a given set of saturation rules. Very briefly, this
means that a constraint is seen as the set of its literals, to which more and more literals are added
according to saturation rules. A saturation rule
of the form | & � �Uo
qb
# | q says that we can add
one of the | q to any constraint that contains at
least the literals in | &
. We only apply rules where
each possible choice adds new literals to the set; a
constraint is saturated under a set � of saturation
rules if no rule in � can add anything else. solve
returns the set of all possible saturations of its input. If the rule system contains nondeterministic distribution rules, with ?� , this set can be
non-singleton; but the rules we are going to introduce are all deterministic propagation rules (with

c
 ).
6.2 Solving Beta Reduction Constraints
The main problem in doing underspecified
 
reduction is that we may not know to which part
of a redex a certain node belongs (as in Fig. 1).
We address this problem by introducing underspecified correspondence literals of the form
co
T9v�T � # w

# V wyyyw T �
o
w
o
V  V`T Q Vc % y
Such a literal is satisfied if the tree segments
denoted by the
�
's and by the  's do not
overlap properly, and there is an r for which
co
T �
q
w
q
V`T Q Vec %
is satisfied.
In Fig. 7 we present the rules UB for underspecified
 
-reduction; the first five rules are the
core of the algorithm. To keep the rules short, we
use the following abbreviations (with $srs ):
beta
cP�����T �Pw��w
 
V
�
� T �
y
w�
y
w
 �y
# wyyy2w
 �yo
V
coq
cP����
co
T9v�T �@w��
y
V w T ��w�
y
V w T
 
w
  yq
V  V
The procedure solve consists of UB together
with the propagation rules from (Bodirsky et al.,
2001). The rest of this section shows how this
procedure operates and what it can and cannot do.
First, we discuss the five core rules. Rule
(Beta) states that whenever the
 
-reduction relation holds, group parallelism holds, too. (This allows us to fall back on a complete solver for group
parallelism.) Rule (Var) introduces a new variable
as a correspondent of a redex variable, and (Lab)
and (Dom) copy labeling and dominance literals
from the redex to the reduct. To understand the
exceptions they make, consider e.g. Fig. 5. Every
node below 
&
has a correspondent in the reduct,
except for 
(
. Every labeling relation in the redex
also holds in the reduct, except for the labelings of
the
�
-node 
#
, the
� ���
-node 
(
, and the  �
-node

4
. For the variables that possess a correspondent, all dominance relations in the redex hold in
the reduct too. The rule (� .Inv) copies inverse � binding literals, i.e. the information that all variables bound by a � -binder are known. For now,
(Beta) �I�7���U���7�e�� ���7���k�1���k�'��8��Ե���H�k�'��� � ���7�t�U�k�2�����9����1�g֢�I�7�X���1�X�k�5����ԵԵ�H���5���
(Var) beta � redex�2���7�t�U�k�1� �����W�Iڤ�ܸצ�n� � �p� � � � co�t�I�'�  � �
(Lab) beta � redex� ���7�t�U�k�1� צ�g�� �H�I� � �9������k�x�9�צ� ���
� co�����
�
�  �5�� �e�g� �1� ���W�H�eܦ��� � � ��ʮ� � �f�� � �H�I�f�� ɵ��Ե�H�k�5�� �
(Dom) beta � �n��8� � co�����
�
�  �5�� צ� � � � � �
� �5�� � � �f�
�
(� .Inv) beta� redex� �I�7���n���7�9�f�� � �I�g�� �� � � ��ԵԵ�H�k�g�D�`� � ��8�
� co� �I�
�
�  � �� � �� � ��� �� � �� � �� ���9������ �� � redex linear
(Par.part) beta� � co���I�'�  � � � � �� ���7�צ�fڤ� � � � � ��� ��� � �
#W�
q
�
o
(Par.all) co� � �I�e��� � �����9���t�8�t���7�  � � צ� ��� ���C� � � � ��� ��� � �H� co���e��� � ���I�'�  � �
Figure 7: New saturation rules UB for constraint solving during underspecified
 
-reduction.
it is restricted to linear redexes; for the nonlinear
case, we have to take recourse to disambiguation.
It can be shown that the rules in UB are sound
in the sense that they are valid implications when
interpreted over � -structures.
6.3 Some Examples
To see what the rules do, we go through the first
reduction step in Fig. 1. The
 
-reduction constraint that belongs to this reduction is
T �@w��w
 
V
�
� T �
y
w�
y
w
 �y
# V
with
� c "d#�%7& w � c %�#�%7( w
 
c %54  w
�
y
c "P3aAC& w�
y
c AD&aAC( w
 �y
# c AD( 
Now saturation can add more constraints, for
example the following:
�
#
� �a� � � � �
6
� �a� � �a�
�
3
� � � � � � �
)
��� � � ����� � � (Lab)
�
(
� � � � �co� � �a� �  � � (Var) �
0
��� � � � � � (Dom)
�
4
� � � � �co� � � � �  � � (Var)
We get (1), (2), (5) by propagation rules from
(Bodirsky et al., 2001): variables bearing different labels must be different. Now we can apply
(Var) to get (3) and (4), then (Lab) to get (6). Finally, (7) shows one of the dominances added by
(Dom). Copies of all other variables and literals
can be computed in a completely analogous fashion. In particular, copying gives us another redex
starting at
ADB
, and we can continue with the algorithm usb in Figure 6.
Note what happens in case of a nonlinear redex,
as in the left picture of Fig. 8: as the redex is � ary, the rules produce two copies of the ! labeling
constraint, one via co
#
and one via co
3
. The result
is shown on the right-hand side of the figure. We
will return to this example in a minute.
6.4 More Complex Examples
The last two rules in Fig. 7 enforce consistency
between scoping in the redex and scoping in the
reduct. The rules use literals that were introduced
in (Bodirsky et al., 2001), of the forms
Q

T
 
V
,
Q 
�
T � V
, etc., where   ,
�
are segment terms.
We take
Q

T
 
V
to mean that
Q
must be inside
the tree segment denoted by   , and we take
Q

�
T � V
(i for 'interior') to mean that
Q

T � V
and
Q
denotes neither the root nor a hole of
�
.
As an example, reconsider Fig. 3: by rule
(Par.part), the reduct (right-hand picture of Fig.
3) cannot represent the term
i T ! TtpHT q VVV
because
that would require the ! operator to be in �
T �
y
V
.
Similarly in Fig. 8, where we have introduced
two copies of the ! label. If the ! in the redex
on the left ends up as part of the context, there
should be only one copy in the reduct. This is
brought about by the rule (Par.all) and the fact that
correspondence is a function (which is enforced
by rules from (Erk et al., 2001) which are part of
the solver in (Bodirsky et al., 2001)). Together,
they can be used to infer that
AD&
can have only
one correspondent in the reduct context.
7 Conclusion
In this paper, we have shown how to perform an
underspecified
 
-reduction operation in the CLLS
framework. This operation transforms underspecified descriptions of higher-order formulas into
descriptions of their
 
-reducts. It can be used to
essentially
 
-reduce all readings of an ambiguous
sentence at once.
It is interesting to observe how our underspecified
 
-reduction interacts with parallelism
constraints that were introduced to model ellipses. Consider the elliptical three-reading example "Peter sees a loophole. Every lawyer does
too." Under the standard analysis of ellipsis in
CLLS (Egg et al., 2001), "Peter" must be represented as a generalized quantifier to obtain all
three readings. This leads to a spurious ambigu�
� ���

�
 �  G`8G 
�
 � �@�EI
� ���
� �� ����
 �E
! AD&
A #

�
� ���
� �� ����
 �
 G`8G 
�
� ���
� �� ����
 �
�@�b
! !
A
y
&
A
y
#
A
y y
&
A
y y
#
Figure 8: "Peter and Mary do not laugh."
ity in the source sentence, which one would like
to get rid of by
 
-reducing the source sentence.
Our approach can achieve this goal: Adding
 
-reduction constraints for the source sentence
leaves the original copy intact, and the target sentence still contains the ambiguity.
Under the simplifying assumption that all redexes are linear, we can show that it takes time
� T�

( V
to perform
�
steps of underspecified
 
reduction on a constraint with  variables. This
is feasible for large
�
as long as 

, which
should be sufficient for most reasonable sentences. If there are non-linear redexes, the present
algorithm can take exponential time because subterms are duplicated. The same problem is known
in ordinary � -calculus; an interesting question to
pursue is whether the sharing techniques developed there (Lamping, 1990) carry over to the underspecification setting.
In Sec. 6, we only employ propagation rules;
that is, we never disambiguate. This is conceptually very nice, but on more complex examples
(e.g. in many cases with nonlinear redexes) disambiguation is still needed.
This raises both theoretical and practical issues.
On the theoretical level, the questions of completeness (elimination of all redexes) and confluence still have to be resolved. To that end, we
first have to find suitable notions of completeness
and confluence in our setting. Also we would like
to handle larger classes of examples without disambiguation. On the practical side, we intend to
implement the procedure and disambiguate in a
controlled fashion so we can reduce completely
and still disambiguate as little as possible.
References
M. Bodirsky, K. Erk, A. Koller, and J. Niehren. 2001.
Beta reduction constraints. In Proc. 12th Rewriting
Techniques and Applications, Utrecht.
J. Bos. 1996. Predicate logic unplugged. In Proceedings of the 10th Amsterdam Colloquium.
R. Cooper. 1983. Quantification and Syntactic Theory. Reidel, Dordrecht.
M. Egg, A. Koller, and J. Niehren. 2001. The constraint language for lambda structures. Journal of
Logic, Language, and Information. To appear.
K. Erk and J. Niehren. 2000. Parallelism constraints.
In Proc. 11th RTA, LNCS 1833.
K. Erk, A. Koller, and J. Niehren. 2001. Processing
underspecified semantic representations in the Constraint Language for Lambda Structures. Journal of
Language and Computation. To appear.
A. Koller and J. Niehren. 2000. On underspecified
processing of dynamic semantics. In Proc. 18th
COLING, Saarbr�
ucken.
A. Koller, J. Niehren, and K. Striegnitz. 2000. Relaxing underspecified semantic representations for
reinterpretation. Grammars, 3(2/3). Special Issue
on MOL'99. To appear.
J. Lamping. 1990. An algorithm for optimal lambda
calculus reduction. In ACM Symp. on Principles of
Programming Languages.
M. P. Marcus, D. Hindle, and M. M. Fleck. 1983. Dtheory: Talking about talking about trees. In Proc.
21st ACL.
R. Montague. 1974. The proper treatment of quantification in ordinary English. In Formal Philosophy.
Selected Papers of Richard Montague. Yale UP.
M. Pinkal. 1996. Radical underspecification. In Proc.
10th Amsterdam Colloquium.
O. Rambow, K. Vijay-Shanker, and D. Weir. 1995.
D-Tree Grammars. In Proceedings of ACL'95.
U. Reyle. 1993. Dealing with ambiguities by underspecification: construction, representation, and deduction. Journal of Semantics, 10.
K. van Deemter and S. Peters. 1996. Semantic Ambiguity and Underspecification. CSLI Press, Stanford.

